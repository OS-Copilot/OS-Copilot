MODEL_NAME="gpt-3.5-turbo-0125"
MODEL_TYPE="OpenAI" # if use the gpt series (OpenAI), lamma series (LLAMA)
OPENAI_API_KEY=""
OPENAI_ORGANIZATION=""
API_BASE_URL="http://127.0.0.1:8079"
OPENAI_BASE_URL=""
BING_SUBSCRIPTION_KEY=""
BING_SEARCH_URL="https://api.bing.microsoft.com/v7.0/search"
WOLFRAMALPHA_APP_ID=""

# LLAMA in local server
# open llama3 at local server
# curl -fsSL https://ollama.com/install.sh | sh
# ollama run llama3
# export NO_PROXY=localhost,127.0.0.1 
# MODEL_NAME="llama3"
# MODEL_TYPE="LLAMA" # if use the gpt series (GPT), lamma series (LLAMA)
# MODEL_SERVER="http://localhost:11434" # only for local model
# test script
# python test_llama3.py

